{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sketcher.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminjacobreji/quickdraw-cnn-demo/blob/main/Sketcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H3ATAdp_URp"
      },
      "source": [
        "# Get the Class names "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlx6-LFL_jbi"
      },
      "source": [
        "This file contains a subset of the quick draw classes. I choose around 3 classes from the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXv-xzU1sd88"
      },
      "source": [
        "# !wget 'https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt'\n",
        "!wget 'https://raw.githubusercontent.com/benjaminjacobreji/quickdraw-cnn-demo/main/fruits.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GL_TdMffD6-"
      },
      "source": [
        "Read the classes names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP-OxOx5sy0b"
      },
      "source": [
        "f = open(\"fruits.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTE6D3uxtMc5"
      },
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]\n",
        "for item in classes:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDfBHVjACAt"
      },
      "source": [
        "# Download the Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MC_PUS-fKjH"
      },
      "source": [
        "Loop over the classes and download the currospondent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSUnpL0u22Q"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DPhL5FtWcQ"
      },
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jF6TXXu-Bu"
      },
      "source": [
        "download() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdnbBVXAI-X"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2FYrPgOKh6t"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o30ipBPAQ5Y"
      },
      "source": [
        "# Load the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBq3GXEKAYuO"
      },
      "source": [
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEIgQNHYQnl"
      },
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 5000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uUjN-WL2Y9"
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGEDS0SMgLK"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZmQvBWBBHE"
      },
      "source": [
        "Show some random data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfpDaHRkyMQC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8InHz5NBFrV"
      },
      "source": [
        "# Preprocess the Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHUq7D2r9e"
      },
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL6XAb4hBMSc"
      },
      "source": [
        "# The Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYUVV2wf2z8H"
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.keras.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YRSRkOyBP1P"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OMEJ7kF3lsP"
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KztY7qEn9_"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssaZczS7DxeA"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xBM_w0VBbNr"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3JfoiYHdpk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPp5D82YBhM-"
      },
      "source": [
        "# Store the classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFI1msFYpCN"
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfJ6dpaDBpRx"
      },
      "source": [
        "# Install TensorFlowJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJDfp9mY9Xh"
      },
      "source": [
        "!pip install tensorflowjs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oBl0ZKVB00d"
      },
      "source": [
        "# Save and Convert "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVICB3TbZGb2"
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWWlGdWZOvs"
      },
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKYxE2MEB6LV"
      },
      "source": [
        "# Zip and Download "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "865-t79uaB63"
      },
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC-MzW8ZXTa"
      },
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}