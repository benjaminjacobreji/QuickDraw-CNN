{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H3ATAdp_URp"
   },
   "source": [
    "# Get the Class names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlx6-LFL_jbi"
   },
   "source": [
    "This file contains a subset of the quick draw classes. I choose around 3 classes from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XXv-xzU1sd88"
   },
   "outputs": [],
   "source": [
    "!wget 'https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GL_TdMffD6-"
   },
   "source": [
    "Read the classes names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eP-OxOx5sy0b"
   },
   "outputs": [],
   "source": [
    "f = open(\"fruits.txt\",\"r\")\n",
    "# And for reading use\n",
    "classes = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lTE6D3uxtMc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "banana\n",
      "strawberry\n"
     ]
    }
   ],
   "source": [
    "classes = [c.replace('\\n','').replace(' ','_') for c in classes]\n",
    "for item in classes:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NDfBHVjACAt"
   },
   "source": [
    "# Download the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MC_PUS-fKjH"
   },
   "source": [
    "Loop over the classes and download the currospondent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rdSUnpL0u22Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "22DPhL5FtWcQ"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def download():\n",
    "  \n",
    "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
    "  for c in classes:\n",
    "    cls_url = c.replace('_', '%20')\n",
    "    path = base+cls_url+'.npy'\n",
    "    print(path)\n",
    "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O5jF6TXXu-Bu",
    "outputId": "e5e42f47-ec7d-421a-a8fc-ae4d078102d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/banana.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/strawberry.npy\n"
     ]
    }
   ],
   "source": [
    "download() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEdnbBVXAI-X"
   },
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "J2FYrPgOKh6t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6o30ipBPAQ5Y"
   },
   "source": [
    "# Load the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBq3GXEKAYuO"
   },
   "source": [
    "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6HEIgQNHYQnl"
   },
   "outputs": [],
   "source": [
    "def load_data(root, vfold_ratio=0.2, max_items_per_class= 5000 ):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "    #initialize variables \n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    #load each data file \n",
    "    for idx, file in enumerate(all_files):\n",
    "        data = np.load(file)\n",
    "        # data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "        class_names.append(class_name)\n",
    "\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    #randomize the dataset \n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    x = x[permutation, :]\n",
    "    y = y[permutation]\n",
    "\n",
    "    #separate into training and testing \n",
    "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
    "\n",
    "    x_test = x[0:vfold_size, :]\n",
    "    y_test = y[0:vfold_size]\n",
    "\n",
    "    x_train = x[vfold_size:x.shape[0], :]\n",
    "    y_train = y[vfold_size:y.shape[0]]\n",
    "    return x_train, y_train, x_test, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K6uUjN-WL2Y9"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
    "num_classes = len(class_names)\n",
    "image_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VhGEDS0SMgLK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459968\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNZmQvBWBBHE"
   },
   "source": [
    "Show some random data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KfpDaHRkyMQC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_train))\n",
    "plt.imshow(x_train[idx].reshape(28,28)) \n",
    "print(class_names[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8InHz5NBFrV"
   },
   "source": [
    "# Preprocess the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "p2GHUq7D2r9e"
   },
   "outputs": [],
   "source": [
    "# Reshape and normalize\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rL6XAb4hBMSc"
   },
   "source": [
    "# The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uYUVV2wf2z8H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 97,539\n",
      "Trainable params: 97,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Convolution2D(16, (3, 3),\n",
    "                        padding='same',\n",
    "                        input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax')) \n",
    "# Train model\n",
    "adam = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['top_k_categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YRSRkOyBP1P"
   },
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7OMEJ7kF3lsP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1618/1618 - 6s - loss: 0.1015 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0626 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "1618/1618 - 6s - loss: 0.0562 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0549 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1618/1618 - 6s - loss: 0.0486 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0500 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1618/1618 - 6s - loss: 0.0439 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0494 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1618/1618 - 6s - loss: 0.0405 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0468 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1618/1618 - 6s - loss: 0.0376 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0461 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1618/1618 - 6s - loss: 0.0346 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0474 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1618/1618 - 6s - loss: 0.0320 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0485 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1618/1618 - 6s - loss: 0.0294 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0488 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1618/1618 - 6s - loss: 0.0267 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0517 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1618/1618 - 6s - loss: 0.0243 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0559 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1618/1618 - 6s - loss: 0.0221 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0566 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1618/1618 - 6s - loss: 0.0198 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0624 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1618/1618 - 6s - loss: 0.0181 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0658 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1618/1618 - 6s - loss: 0.0167 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0694 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1618/1618 - 6s - loss: 0.0145 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0731 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1618/1618 - 6s - loss: 0.0137 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0837 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1618/1618 - 6s - loss: 0.0124 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0789 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1618/1618 - 6s - loss: 0.0115 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0888 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1618/1618 - 6s - loss: 0.0103 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0867 - val_top_k_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe07482ce50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2KztY7qEn9_"
   },
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ssaZczS7DxeA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuarcy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xBM_w0VBbNr"
   },
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nH3JfoiYHdpk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'strawberry', 'apple']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_test))\n",
    "img = x_test[idx]\n",
    "plt.imshow(img.squeeze()) \n",
    "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "ind = (-pred).argsort()[:5]\n",
    "latex = [class_names[x] for x in ind]\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPp5D82YBhM-"
   },
   "source": [
    "# Store the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NoFI1msFYpCN"
   },
   "outputs": [],
   "source": [
    "with open('class_names.txt', 'w') as file_handler:\n",
    "    for item in class_names:\n",
    "        file_handler.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfJ6dpaDBpRx"
   },
   "source": [
    "# Install TensorFlowJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hJJDfp9mY9Xh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflowjs in /home/benjamin/miniconda3/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: tensorflow-hub<0.10,>=0.7.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflowjs) (0.9.0)\n",
      "Requirement already satisfied: h5py<3,>=2.8.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflowjs) (2.10.0)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflowjs) (1.15.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflowjs) (2.2.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (1.19.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.31.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.2.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
      "Requirement already satisfied: setuptools in /home/benjamin/miniconda3/lib/python3.8/site-packages (from protobuf>=3.8.0->tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (50.3.0.post20201006)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.6.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.22.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (2020.6.20)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/benjamin/miniconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/benjamin/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oBl0ZKVB00d"
   },
   "source": [
    "# Save and Convert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XVICB3TbZGb2"
   },
   "outputs": [],
   "source": [
    "model.save('keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bTWWlGdWZOvs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir model\n",
    "!tensorflowjs_converter --input_format keras keras.h5 model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKYxE2MEB6LV"
   },
   "source": [
    "# Zip and Download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "865-t79uaB63"
   },
   "outputs": [],
   "source": [
    "!cp class_names.txt model/class_names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GLC-MzW8ZXTa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: model/ (stored 0%)\r\n",
      "updating: model/group1-shard1of1.bin (deflated 7%)\r\n",
      "updating: model/model.json (deflated 82%)\r\n",
      "updating: model/class_names.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r model.zip model "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sketcher.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}